# Overview
This repository contains a Retrieval-Augmented Generation (RAG) AI model implementation using the LLAMA 2 model, specifically TheBloke/Llama-2-7B-chat-GGUF/llama-2-7b-chat.Q3_K_S.gguf. 
The model is deployed and running on a local machine with the following specifications:

RAM: 8GB

Storage: 512GB SSD

GPU: GTX 1650

# Features
Retrieval-Augmented Generation (RAG): Combines the power of retrieval-based models and generative models to produce accurate and contextually relevant responses.

LLAMA 2 Model: Utilizes the advanced capabilities of the LLAMA 2 model to enhance the AI's understanding and generation of human-like text.

Optimized for Local Machine: Efficiently runs on a machine with moderate specifications, making it accessible for individual developers and researchers.
